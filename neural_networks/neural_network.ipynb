{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Select relevant features\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "label = \"Survived\"\n",
    "\n",
    "# Fill missing values\n",
    "df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
    "df[\"Fare\"].fillna(df[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# Convert categorical variables\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# Normalize numerical columns (Min-Max Scaling)\n",
    "for col in [\"Age\", \"Fare\"]:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "# Extract features and labels\n",
    "X = df[features].values.tolist()  # Convert to pure Python list\n",
    "y = df[label].values.tolist()      # Convert labels to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.26123853039547285\n",
      "Epoch 100: Loss = 0.14270303087257555\n",
      "Epoch 200: Loss = 0.13943654200885547\n",
      "Epoch 300: Loss = 0.1367286314636621\n",
      "Epoch 400: Loss = 0.13476712315046682\n",
      "Epoch 500: Loss = 0.13345825266375086\n",
      "Epoch 600: Loss = 0.13250017533794897\n",
      "Epoch 700: Loss = 0.13171858983753543\n",
      "Epoch 800: Loss = 0.13103983000798963\n",
      "Epoch 900: Loss = 0.130431535672393\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    \"\"\"Numerically stable sigmoid function to prevent overflow issues.\"\"\"\n",
    "    if x < -500:\n",
    "        return 0  # Avoid overflow for large negative values\n",
    "    elif x > 500:\n",
    "        return 1  # Avoid underflow for large positive values\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)  # Derivative of sigmoid\n",
    "\n",
    "# Initialize network with random weights\n",
    "def initialize_network(input_size, hidden_size, output_size):\n",
    "    network = {\n",
    "        # ✅ Fix: Ensure each row in W1 corresponds to an input feature\n",
    "        \"W1\": [[random.uniform(-1, 1) for _ in range(hidden_size)] for _ in range(input_size)],\n",
    "        \"B1\": [random.uniform(-1, 1) for _ in range(hidden_size)],\n",
    "\n",
    "        # ✅ Fix: Ensure each row in W2 corresponds to a hidden neuron\n",
    "        \"W2\": [[random.uniform(-1, 1) for _ in range(output_size)] for _ in range(hidden_size)],\n",
    "        \"B2\": [random.uniform(-1, 1) for _ in range(output_size)],\n",
    "    }\n",
    "    return network\n",
    "\n",
    "# Forward pass\n",
    "def forward_pass(network, inputs):\n",
    "    # ✅ Fix: Ensure correct iteration over the hidden layer\n",
    "    hidden_layer_input = [\n",
    "        sum(inputs[j] * network[\"W1\"][j][i] for j in range(len(inputs))) + network[\"B1\"][i]\n",
    "        for i in range(len(network[\"B1\"]))\n",
    "    ]\n",
    "    hidden_layer_output = [sigmoid(x) for x in hidden_layer_input]\n",
    "\n",
    "    # ✅ Fix: Ensure correct iteration over the output layer\n",
    "    output_layer_input = [\n",
    "        sum(hidden_layer_output[h] * network[\"W2\"][h][o] for h in range(len(hidden_layer_output))) + network[\"B2\"][o]\n",
    "        for o in range(len(network[\"B2\"]))\n",
    "    ]\n",
    "    output_layer_output = [sigmoid(x) for x in output_layer_input]\n",
    "\n",
    "    return hidden_layer_output, output_layer_output\n",
    "\n",
    "# Backpropagation\n",
    "def backward_pass(network, inputs, hidden_output, output_output, expected, learning_rate=0.1):\n",
    "    output_errors = [(expected[i] - output_output[i]) for i in range(len(expected))]\n",
    "    output_deltas = [output_errors[i] * sigmoid_derivative(output_output[i]) for i in range(len(expected))]\n",
    "\n",
    "    hidden_errors = [sum(output_deltas[o] * network[\"W2\"][h][o] for o in range(len(output_deltas))) for h in range(len(hidden_output))]\n",
    "    hidden_deltas = [hidden_errors[h] * sigmoid_derivative(hidden_output[h]) for h in range(len(hidden_output))]\n",
    "\n",
    "    # Update output layer weights\n",
    "    for h in range(len(network[\"W2\"])):\n",
    "        for o in range(len(network[\"W2\"][h])):\n",
    "            network[\"W2\"][h][o] += learning_rate * output_deltas[o] * hidden_output[h]\n",
    "\n",
    "    # Update output layer biases\n",
    "    for o in range(len(network[\"B2\"])):\n",
    "        network[\"B2\"][o] += learning_rate * output_deltas[o]\n",
    "\n",
    "    # Update hidden layer weights\n",
    "    for i in range(len(network[\"W1\"])):\n",
    "        for h in range(len(network[\"W1\"][i])):\n",
    "            network[\"W1\"][i][h] += learning_rate * hidden_deltas[h] * inputs[i]\n",
    "\n",
    "    # Update hidden layer biases\n",
    "    for h in range(len(network[\"B1\"])):\n",
    "        network[\"B1\"][h] += learning_rate * hidden_deltas[h]\n",
    "\n",
    "# Train the network\n",
    "def train_network(network, X, y, epochs=1000, learning_rate=0.1):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, expected in zip(X, y):\n",
    "            expected = [expected]  # Convert to list for compatibility\n",
    "            hidden_output, output_output = forward_pass(network, inputs)\n",
    "            backward_pass(network, inputs, hidden_output, output_output, expected, learning_rate)\n",
    "            total_loss += sum((expected[i] - output_output[i]) ** 2 for i in range(len(expected)))  # MSE loss\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {total_loss / len(X)}\")\n",
    "\n",
    "# Initialize and train\n",
    "network = initialize_network(input_size=len(X[0]), hidden_size=15, output_size=1)\n",
    "train_network(network, X, y, epochs=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 83.16%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "correct = 0\n",
    "for inputs, expected in zip(X, y):\n",
    "    _, output_output = forward_pass(network, inputs)\n",
    "    prediction = 1 if output_output[0] > 0.5 else 0\n",
    "    correct += int(prediction == expected)\n",
    "\n",
    "print(f\"✅ Accuracy: {correct / len(X) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
