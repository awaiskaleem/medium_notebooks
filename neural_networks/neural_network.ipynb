{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Select relevant features\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "label = \"Survived\"\n",
    "\n",
    "# Fill missing values\n",
    "df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
    "df[\"Fare\"].fillna(df[\"Fare\"].median(), inplace=True)\n",
    "\n",
    "# Convert categorical variables\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# Normalize numerical columns (Min-Max Scaling)\n",
    "for col in [\"Age\", \"Fare\"]:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "# Extract features and labels\n",
    "X = df[features].values  # Convert to NumPy array\n",
    "y = df[label].values.reshape(-1, 1)  # Ensure it's a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.2671, Accuracy = 0.3904\n",
      "Epoch 100: Loss = 0.1439, Accuracy = 0.8076\n",
      "Epoch 200: Loss = 0.1420, Accuracy = 0.8062\n",
      "Epoch 300: Loss = 0.1405, Accuracy = 0.8034\n",
      "Epoch 400: Loss = 0.1396, Accuracy = 0.8062\n",
      "Epoch 500: Loss = 0.1390, Accuracy = 0.8048\n",
      "Epoch 600: Loss = 0.1385, Accuracy = 0.8090\n",
      "Epoch 700: Loss = 0.1381, Accuracy = 0.8104\n",
      "Epoch 800: Loss = 0.1377, Accuracy = 0.8076\n",
      "Epoch 900: Loss = 0.1373, Accuracy = 0.8090\n",
      "\n",
      "Test Accuracy: 0.8492\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)  # Prevent extreme values\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Initialize network with random weights and biases\n",
    "def initialize_network(input_size, hidden_size, output_size):\n",
    "    return {\n",
    "        \"W1\": np.random.uniform(-1, 1, (input_size, hidden_size)),  # (input_size, hidden_size)\n",
    "        \"B1\": np.random.uniform(-1, 1, (1, hidden_size)),           # (1, hidden_size)\n",
    "        \"W2\": np.random.uniform(-1, 1, (hidden_size, output_size)), # (hidden_size, output_size)\n",
    "        \"B2\": np.random.uniform(-1, 1, (1, output_size))            # (1, output_size)\n",
    "    }\n",
    "\n",
    "# Forward pass\n",
    "def forward_pass(network, inputs):\n",
    "    hidden_layer_input = np.dot(inputs, network[\"W1\"]) + network[\"B1\"]\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, network[\"W2\"]) + network[\"B2\"]\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "    return hidden_layer_input, hidden_layer_output, output_layer_input, output_layer_output\n",
    "\n",
    "# Backpropagation\n",
    "def backward_pass(network, inputs, hidden_layer_input, hidden_output, output_output, expected, learning_rate):\n",
    "    output_errors = expected - output_output  # Error at output\n",
    "    output_deltas = output_errors * sigmoid_derivative(output_output)  # Gradient at output\n",
    "\n",
    "    hidden_errors = np.dot(output_deltas, network[\"W2\"].T)  # Backpropagated error\n",
    "    hidden_deltas = hidden_errors * sigmoid_derivative(hidden_output)  # Gradient at hidden layer\n",
    "\n",
    "    # Update weights and biases\n",
    "    network[\"W2\"] += learning_rate * np.dot(hidden_output.T, output_deltas)\n",
    "    network[\"B2\"] += learning_rate * np.sum(output_deltas, axis=0, keepdims=True)\n",
    "\n",
    "    network[\"W1\"] += learning_rate * np.dot(inputs.T, hidden_deltas)\n",
    "    network[\"B1\"] += learning_rate * np.sum(hidden_deltas, axis=0, keepdims=True)\n",
    "\n",
    "# Train the network\n",
    "def train_network(network, X, y, epochs=1000, learning_rate=0.1):\n",
    "    for epoch in range(epochs):\n",
    "        hidden_layer_input, hidden_output, output_layer_input, output_output = forward_pass(network, X)\n",
    "        backward_pass(network, X, hidden_layer_input, hidden_output, output_output, y, learning_rate)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            loss = np.mean((y - output_output) ** 2)  # MSE Loss\n",
    "            accuracy = np.mean((output_output >= 0.5) == y)  # Binary classification accuracy\n",
    "            print(f\"Epoch {epoch}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Split dataset into training and testing\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Initialize and train\n",
    "network = initialize_network(input_size=X.shape[1], hidden_size=10, output_size=1)\n",
    "train_network(network, X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Evaluate on test set\n",
    "_, _, _, test_output = forward_pass(network, X_test)\n",
    "test_accuracy = np.mean((test_output >= 0.5) == y_test)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
